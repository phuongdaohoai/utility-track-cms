import { useRef, useEffect, useState } from 'react'
import * as faceapi from 'face-api.js'
import { loadFaceModels } from '../utils/faceApi'

interface FaceIDScannerProps {
  onScan: (descriptor: number[]) => void
  onClose: () => void
  title?: string
}

/**
 * Xin quy·ªÅn camera tr∆∞·ªõc (UX chu·∫©n)
 */
const requestCameraPermission = async (): Promise<boolean> => {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ video: true })
    stream.getTracks().forEach(track => track.stop())
    return true
  } catch {
    return false
  }
}

export const FaceIDScanner: React.FC<FaceIDScannerProps> = ({
  onScan,
  onClose,
  title = 'Qu√©t Face ID',
}) => {
  const videoRef = useRef<HTMLVideoElement>(null)
  const streamRef = useRef<MediaStream | null>(null)

  const [error, setError] = useState<string | null>(null)
  const [loading, setLoading] = useState(true)
  const [capturing, setCapturing] = useState(false)

  /**
   * B·∫Øt ƒë·∫ßu camera
   */
  const startCamera = async () => {
    try {
      setError(null)
      setLoading(true)

      // 1Ô∏è‚É£ Load model FaceAPI
      await loadFaceModels()

      // 2Ô∏è‚É£ Xin quy·ªÅn camera
      const granted = await requestCameraPermission()
      if (!granted) {
        setError('B·∫°n c·∫ßn cho ph√©p truy c·∫≠p camera')
        setLoading(false)
        return
      }

      // 3Ô∏è‚É£ M·ªü camera
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: 'user' },
      })

      streamRef.current = stream

      if (videoRef.current) {
        videoRef.current.srcObject = stream
        await videoRef.current.play()
      }

      setLoading(false)
    } catch (err: any) {
      console.error(err)

      if (err.name === 'NotAllowedError') {
        setError('B·∫°n ƒë√£ t·ª´ ch·ªëi quy·ªÅn camera')
      } else if (err.name === 'NotFoundError') {
        setError('Kh√¥ng t√¨m th·∫•y camera')
      } else {
        setError('Kh√¥ng th·ªÉ truy c·∫≠p camera')
      }

      setLoading(false)
    }
  }

  /**
   * D·ª´ng camera
   */
  const stopCamera = () => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop())
      streamRef.current = null
    }

    if (videoRef.current) {
      videoRef.current.srcObject = null
    }
  }

  /**
   * Ch·ª•p & l·∫•y Face Descriptor
   */
  const captureFace = async () => {
    if (!videoRef.current || capturing) return

    setCapturing(true)
    setError(null)

    try {
      const detection = await faceapi
        .detectSingleFace(
          videoRef.current,
          new faceapi.TinyFaceDetectorOptions()
        )
        .withFaceLandmarks()
        .withFaceDescriptor()

      if (!detection) {
        setError('Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t')
        setCapturing(false)
        return
      }

      const descriptor = Array.from(detection.descriptor) // Float32Array ‚Üí number[]

      console.log('üß† Face Descriptor (128):', descriptor)

      onScan(descriptor)
      handleClose()
    } catch (err) {
      console.error(err)
      setError('L·ªói khi x·ª≠ l√Ω khu√¥n m·∫∑t')
    } finally {
      setCapturing(false)
    }
  }

  /**
   * ƒê√≥ng modal
   */
  const handleClose = () => {
    stopCamera()
    onClose()
  }

  /**
   * Lifecycle
   */
  useEffect(() => {
    startCamera()
    return stopCamera
  }, [])

  return (
    <div className="fixed inset-0 z-50 bg-black bg-opacity-75 flex items-center justify-center">
      <div className="bg-white rounded-lg p-6 w-full max-w-2xl mx-4">
        {/* Header */}
        <div className="flex justify-between items-center mb-4">
          <h2 className="text-xl font-bold">{title}</h2>
          <button onClick={handleClose} className="text-2xl text-gray-500">
            √ó
          </button>
        </div>

        {/* Error */}
        {error && (
          <div className="mb-4 bg-red-100 border border-red-400 text-red-700 px-4 py-3 rounded">
            {error}
          </div>
        )}

        {/* Video */}
        {!error && (
          <div className="relative">
            {loading ? (
              <div className="h-64 flex items-center justify-center text-gray-500">
                ƒêang kh·ªüi ƒë·ªông camera...
              </div>
            ) : (
              <>
                <video
                  ref={videoRef}
                  className="w-full rounded-lg"
                  autoPlay
                  muted
                  playsInline
                />

                {/* Overlay */}
                <div className="absolute inset-0 flex items-center justify-center pointer-events-none">
                  <div className="w-48 h-48 rounded-full border-4 border-blue-500"></div>
                </div>

                <div className="absolute bottom-2 left-0 right-0 text-center text-white bg-black bg-opacity-50 py-2 rounded">
                  ƒê∆∞a khu√¥n m·∫∑t v√†o khung
                </div>
              </>
            )}
          </div>
        )}

        {/* Actions */}
        <div className="mt-4 flex justify-end gap-2">
          <button
            onClick={handleClose}
            className="bg-gray-500 text-white px-6 py-2 rounded"
          >
            H·ªßy
          </button>

          {!error && !loading && (
            <button
              onClick={captureFace}
              disabled={capturing}
              className="bg-blue-600 text-white px-6 py-2 rounded disabled:bg-gray-400"
            >
              {capturing ? 'ƒêang x·ª≠ l√Ω...' : 'Ch·ª•p ·∫£nh'}
            </button>
          )}
        </div>
      </div>
    </div>
  )
}
